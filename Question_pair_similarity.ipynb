{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theGarimaAgrawal/Question-Pairs-Similarity-Detection-and-Quora-Tag-Generation/blob/master/Question_pair_similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysing the Dataset\n"
      ],
      "metadata": {
        "id": "VeH0L9sHwSH5"
      },
      "id": "VeH0L9sHwSH5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "600ccbe8",
      "metadata": {
        "id": "600ccbe8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60425156",
      "metadata": {
        "id": "60425156",
        "outputId": "3f07f988-cd2c-4c2b-a0bc-216c466a570d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(404290, 6)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"train.csv\")\n",
        "df.shape\n",
        "# 4 lakhs rows - very big data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a3d86b9",
      "metadata": {
        "id": "5a3d86b9",
        "outputId": "d6f09bab-36ac-4f72-d7be-f515d054907b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>183268</th>\n",
              "      <td>183268</td>\n",
              "      <td>280288</td>\n",
              "      <td>280289</td>\n",
              "      <td>How did monkeys get to South America from Afri...</td>\n",
              "      <td>I fucking hate my life, I'm black, poor nd liv...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112930</th>\n",
              "      <td>112930</td>\n",
              "      <td>184684</td>\n",
              "      <td>132960</td>\n",
              "      <td>What is the best photo ever taken in your life?</td>\n",
              "      <td>What is the best picture taken by you?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300075</th>\n",
              "      <td>300075</td>\n",
              "      <td>348955</td>\n",
              "      <td>422827</td>\n",
              "      <td>What are some things new employees should know...</td>\n",
              "      <td>What are some things new employees should know...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223993</th>\n",
              "      <td>223993</td>\n",
              "      <td>296218</td>\n",
              "      <td>184831</td>\n",
              "      <td>Why do the British care about the Royal Family?</td>\n",
              "      <td>Why has the UK retained the monarchy?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171389</th>\n",
              "      <td>171389</td>\n",
              "      <td>177374</td>\n",
              "      <td>264819</td>\n",
              "      <td>Which is the most inspiring book to read?</td>\n",
              "      <td>What is the most inspiring book you have ever ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357002</th>\n",
              "      <td>357002</td>\n",
              "      <td>486390</td>\n",
              "      <td>486391</td>\n",
              "      <td>Why can't I forget my girlfriend?</td>\n",
              "      <td>Why can't I forget my first girlfriend?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348760</th>\n",
              "      <td>348760</td>\n",
              "      <td>477337</td>\n",
              "      <td>477338</td>\n",
              "      <td>Which is greater rise in 1 degree Celsius or r...</td>\n",
              "      <td>If I sit and hold 100 grams of ice at zero deg...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119950</th>\n",
              "      <td>119950</td>\n",
              "      <td>194645</td>\n",
              "      <td>194646</td>\n",
              "      <td>What are some ways to amplify linear motion an...</td>\n",
              "      <td>How do you amplify linear motion?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209885</th>\n",
              "      <td>209885</td>\n",
              "      <td>314294</td>\n",
              "      <td>314295</td>\n",
              "      <td>How should one prepare for IAS when he is in h...</td>\n",
              "      <td>How can I prepare for IAS from my first year o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23430</th>\n",
              "      <td>23430</td>\n",
              "      <td>43885</td>\n",
              "      <td>43886</td>\n",
              "      <td>In the initial days of a SaaS startup, when th...</td>\n",
              "      <td>I have to manage the entire operations and pro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id    qid1    qid2  \\\n",
              "183268  183268  280288  280289   \n",
              "112930  112930  184684  132960   \n",
              "300075  300075  348955  422827   \n",
              "223993  223993  296218  184831   \n",
              "171389  171389  177374  264819   \n",
              "357002  357002  486390  486391   \n",
              "348760  348760  477337  477338   \n",
              "119950  119950  194645  194646   \n",
              "209885  209885  314294  314295   \n",
              "23430    23430   43885   43886   \n",
              "\n",
              "                                                question1  \\\n",
              "183268  How did monkeys get to South America from Afri...   \n",
              "112930    What is the best photo ever taken in your life?   \n",
              "300075  What are some things new employees should know...   \n",
              "223993    Why do the British care about the Royal Family?   \n",
              "171389          Which is the most inspiring book to read?   \n",
              "357002                  Why can't I forget my girlfriend?   \n",
              "348760  Which is greater rise in 1 degree Celsius or r...   \n",
              "119950  What are some ways to amplify linear motion an...   \n",
              "209885  How should one prepare for IAS when he is in h...   \n",
              "23430   In the initial days of a SaaS startup, when th...   \n",
              "\n",
              "                                                question2  is_duplicate  \n",
              "183268  I fucking hate my life, I'm black, poor nd liv...             0  \n",
              "112930             What is the best picture taken by you?             1  \n",
              "300075  What are some things new employees should know...             0  \n",
              "223993              Why has the UK retained the monarchy?             0  \n",
              "171389  What is the most inspiring book you have ever ...             0  \n",
              "357002            Why can't I forget my first girlfriend?             1  \n",
              "348760  If I sit and hold 100 grams of ice at zero deg...             0  \n",
              "119950                  How do you amplify linear motion?             1  \n",
              "209885  How can I prepare for IAS from my first year o...             1  \n",
              "23430   I have to manage the entire operations and pro...             0  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37b00141",
      "metadata": {
        "id": "37b00141",
        "outputId": "262c2ac5-84a2-4e72-d10a-64d42e7a81cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 404290 entries, 0 to 404289\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count   Dtype \n",
            "---  ------        --------------   ----- \n",
            " 0   id            404290 non-null  int64 \n",
            " 1   qid1          404290 non-null  int64 \n",
            " 2   qid2          404290 non-null  int64 \n",
            " 3   question1     404289 non-null  object\n",
            " 4   question2     404288 non-null  object\n",
            " 5   is_duplicate  404290 non-null  int64 \n",
            "dtypes: int64(4), object(2)\n",
            "memory usage: 18.5+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f9bd6af",
      "metadata": {
        "id": "3f9bd6af",
        "outputId": "ff7daa2f-ec77-4bfe-9da9-2ecd79895060"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    255027\n",
            "1    149263\n",
            "Name: is_duplicate, dtype: int64\n",
            "0    63.080215\n",
            "1    36.919785\n",
            "Name: is_duplicate, dtype: float64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Distribution of duplicate and non-duplicate questions\n",
        "\n",
        "print(df['is_duplicate'].value_counts())\n",
        "print((df['is_duplicate'].value_counts()/df['is_duplicate'].count())*100)\n",
        "df['is_duplicate'].value_counts().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "788d2d08",
      "metadata": {
        "id": "788d2d08",
        "outputId": "d8ef557c-b848-4ef6-c661-4be62c8391ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique questions 537933\n",
            "Number of questions getting repeated 111780\n"
          ]
        }
      ],
      "source": [
        "# Repeated questions\n",
        "\n",
        "qid = pd.Series(df['qid1'].tolist() + df['qid2'].tolist())\n",
        "print('Number of unique questions',np.unique(qid).shape[0])\n",
        "x = qid.value_counts()>1\n",
        "print('Number of questions getting repeated',x[x].shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fa5bb83",
      "metadata": {
        "id": "2fa5bb83",
        "outputId": "bef25e75-760a-4cbd-d446-0581518edb6a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Repeated questions histogram\n",
        "\n",
        "plt.hist(qid.value_counts().values,bins=160)\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9573e2f",
      "metadata": {
        "id": "f9573e2f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag of words approach\n"
      ],
      "metadata": {
        "id": "3YcON6gAwa75"
      },
      "id": "3YcON6gAwa75"
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df.sample(30000)\n",
        "ques_df = new_df[['question1','question2']]\n",
        "ques_df.head()"
      ],
      "metadata": {
        "id": "r1B-4B8-wezc"
      },
      "id": "r1B-4B8-wezc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "questions = list(ques_df['question1']) + list(ques_df['question2'])\n",
        "# taking only 3000 features otherwise there will be so many words\n",
        "cv = CountVectorizer(max_features=3000)\n",
        "q1_arr, q2_arr = np.vsplit(cv.fit_transform(questions).toarray(),2)"
      ],
      "metadata": {
        "id": "UeubN5FdwnGK"
      },
      "id": "UeubN5FdwnGK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df1 = pd.DataFrame(q1_arr, index= ques_df.index)\n",
        "temp_df2 = pd.DataFrame(q2_arr, index= ques_df.index)\n",
        "temp_df = pd.concat([temp_df1, temp_df2], axis=1)\n",
        "temp_df.shape"
      ],
      "metadata": {
        "id": "PI417GZ1w9v2"
      },
      "id": "PI417GZ1w9v2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df"
      ],
      "metadata": {
        "id": "k3WAUS4OxH-5"
      },
      "id": "k3WAUS4OxH-5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['is_duplicate'] = new_df['is_duplicate']"
      ],
      "metadata": {
        "id": "7F0MMP-dxKQs"
      },
      "id": "7F0MMP-dxKQs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(temp_df.iloc[:,0:-1].values,temp_df.iloc[:,-1].values,test_size=0.2,random_state=1)"
      ],
      "metadata": {
        "id": "xUPh6NmcxRsA"
      },
      "id": "xUPh6NmcxRsA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train,y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "pyPrmRA8xWQa"
      },
      "id": "pyPrmRA8xWQa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "xgb = XGBClassifier()\n",
        "xgb.fit(X_train,y_train)\n",
        "y_pred = xgb.predict(X_test)\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "da-I9IbtxYwS"
      },
      "id": "da-I9IbtxYwS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tUm_Ov7aw9mA"
      },
      "id": "tUm_Ov7aw9mA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag of Words with 7 more features\n",
        "\n"
      ],
      "metadata": {
        "id": "nihC31Djxct1"
      },
      "id": "nihC31Djxct1"
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df.sample(30000,random_state=2)"
      ],
      "metadata": {
        "id": "lNldiKutxgf5"
      },
      "id": "lNldiKutxgf5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['q1_len'] = new_df['question1'].str.len() \n",
        "new_df['q2_len'] = new_df['question2'].str.len()"
      ],
      "metadata": {
        "id": "B2jmVyKhxmnj"
      },
      "id": "B2jmVyKhxmnj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['q1_num_words'] = new_df['question1'].apply(lambda row: len(row.split(\" \")))\n",
        "new_df['q2_num_words'] = new_df['question2'].apply(lambda row: len(row.split(\" \")))"
      ],
      "metadata": {
        "id": "Pu40su27xukt"
      },
      "id": "Pu40su27xukt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head()"
      ],
      "metadata": {
        "id": "mM4yIfgbxyRC"
      },
      "id": "mM4yIfgbxyRC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def common_words(row):\n",
        "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
        "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
        "    return len(w1 & w2)"
      ],
      "metadata": {
        "id": "t8Q0ANZhxy-Q"
      },
      "id": "t8Q0ANZhxy-Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['word_common'] = new_df.apply(common_words, axis=1)"
      ],
      "metadata": {
        "id": "K4dOYffLx01x"
      },
      "id": "K4dOYffLx01x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def total_words(row):\n",
        "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
        "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
        "    return (len(w1) + len(w2))"
      ],
      "metadata": {
        "id": "FzXHvX0tx3K6"
      },
      "id": "FzXHvX0tx3K6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['word_total'] = new_df.apply(total_words, axis=1)"
      ],
      "metadata": {
        "id": "jKZ0LefKx4_N"
      },
      "id": "jKZ0LefKx4_N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['word_share'] = round(new_df['word_common']/new_df['word_total'],2)"
      ],
      "metadata": {
        "id": "wCOzoMinx7iI"
      },
      "id": "wCOzoMinx7iI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis of features\n",
        "sns.displot(new_df['q1_len'])\n",
        "print('minimum characters',new_df['q1_len'].min())\n",
        "print('maximum characters',new_df['q1_len'].max())\n",
        "print('average num of characters',int(new_df['q1_len'].mean()))"
      ],
      "metadata": {
        "id": "IJMdKNjBx9TG"
      },
      "id": "IJMdKNjBx9TG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.displot(new_df['q2_len'])\n",
        "print('minimum characters',new_df['q2_len'].min())\n",
        "print('maximum characters',new_df['q2_len'].max())\n",
        "print('average num of characters',int(new_df['q2_len'].mean()))"
      ],
      "metadata": {
        "id": "CZGoWqleyAGC"
      },
      "id": "CZGoWqleyAGC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.displot(new_df['q1_num_words'])\n",
        "print('minimum words',new_df['q1_num_words'].min())\n",
        "print('maximum words',new_df['q1_num_words'].max())\n",
        "print('average num of words',int(new_df['q1_num_words'].mean()))"
      ],
      "metadata": {
        "id": "XMKwqY2myB5Y"
      },
      "id": "XMKwqY2myB5Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.displot(new_df['q2_num_words'])\n",
        "print('minimum words',new_df['q2_num_words'].min())\n",
        "print('maximum words',new_df['q2_num_words'].max())\n",
        "print('average num of words',int(new_df['q2_num_words'].mean()))"
      ],
      "metadata": {
        "id": "_ijc0QF3yDjx"
      },
      "id": "_ijc0QF3yDjx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# common words\n",
        "sns.distplot(new_df[new_df['is_duplicate'] == 0]['word_common'],label='non duplicate')\n",
        "sns.distplot(new_df[new_df['is_duplicate'] == 1]['word_common'],label='duplicate')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PpOv8Rs2yFQz"
      },
      "id": "PpOv8Rs2yFQz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# total words\n",
        "sns.distplot(new_df[new_df['is_duplicate'] == 0]['word_total'],label='non duplicate')\n",
        "sns.distplot(new_df[new_df['is_duplicate'] == 1]['word_total'],label='duplicate')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FkJ7dLDMyHNQ"
      },
      "id": "FkJ7dLDMyHNQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word share\n",
        "sns.distplot(new_df[new_df['is_duplicate'] == 0]['word_share'],label='non duplicate')\n",
        "sns.distplot(new_df[new_df['is_duplicate'] == 1]['word_share'],label='duplicate')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kKVfuHyqyJBI"
      },
      "id": "kKVfuHyqyJBI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = new_df.drop(columns=['id','qid1','qid2','question1','question2'])\n",
        "print(final_df.shape)\n",
        "final_df.head()"
      ],
      "metadata": {
        "id": "aa953oQiyLGO"
      },
      "id": "aa953oQiyLGO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# merge texts\n",
        "questions = list(ques_df['question1']) + list(ques_df['question2'])\n",
        "\n",
        "cv = CountVectorizer(max_features=3000)\n",
        "q1_arr, q2_arr = np.vsplit(cv.fit_transform(questions).toarray(),2)"
      ],
      "metadata": {
        "id": "ADhQxyRNybtD"
      },
      "id": "ADhQxyRNybtD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df1 = pd.DataFrame(q1_arr, index= ques_df.index)\n",
        "temp_df2 = pd.DataFrame(q2_arr, index= ques_df.index)\n",
        "temp_df = pd.concat([temp_df1, temp_df2], axis=1)\n",
        "temp_df.shape"
      ],
      "metadata": {
        "id": "gKAkaRF1yeGG"
      },
      "id": "gKAkaRF1yeGG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.concat([final_df, temp_df], axis=1)\n",
        "print(final_df.shape)\n",
        "final_df.head()"
      ],
      "metadata": {
        "id": "xBeXD86lygVb"
      },
      "id": "xBeXD86lygVb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(final_df.iloc[:,1:].values,final_df.iloc[:,0].values,test_size=0.2,random_state=1)"
      ],
      "metadata": {
        "id": "BC5bIsa6yiEd"
      },
      "id": "BC5bIsa6yiEd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train,y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "A7AwWZk7yj5y"
      },
      "id": "A7AwWZk7yj5y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "xgb = XGBClassifier()\n",
        "xgb.fit(X_train,y_train)\n",
        "y_pred = xgb.predict(X_test)\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "pDcfzrBdylXC"
      },
      "id": "pDcfzrBdylXC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced features"
      ],
      "metadata": {
        "id": "NO2wl66pyouo"
      },
      "id": "NO2wl66pyouo"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "i9SJua66zEsy"
      },
      "id": "i9SJua66zEsy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess(q):\n",
        "    \n",
        "    q = str(q).lower().strip()\n",
        "    \n",
        "    # Replace certain special characters with their string equivalents\n",
        "    q = q.replace('%', ' percent')\n",
        "    q = q.replace('$', ' dollar ')\n",
        "    q = q.replace('₹', ' rupee ')\n",
        "    q = q.replace('€', ' euro ')\n",
        "    q = q.replace('@', ' at ')\n",
        "    \n",
        "    # The pattern '[math]' appears around 900 times in the whole dataset.\n",
        "    q = q.replace('[math]', '')\n",
        "    \n",
        "    # Replacing some numbers with string equivalents (not perfect, can be done better to account for more cases)\n",
        "    q = q.replace(',000,000,000 ', 'b ')\n",
        "    q = q.replace(',000,000 ', 'm ')\n",
        "    q = q.replace(',000 ', 'k ')\n",
        "    q = re.sub(r'([0-9]+)000000000', r'\\1b', q)\n",
        "    q = re.sub(r'([0-9]+)000000', r'\\1m', q)\n",
        "    q = re.sub(r'([0-9]+)000', r'\\1k', q)\n",
        "    \n",
        "    # Decontracting words\n",
        "    # https://en.wikipedia.org/wiki/Wikipedia%3aList_of_English_contractions\n",
        "    # https://stackoverflow.com/a/19794953\n",
        "    contractions = { \n",
        "    \"ain't\": \"am not\",\n",
        "    \"aren't\": \"are not\",\n",
        "    \"can't\": \"can not\",\n",
        "    \"can't've\": \"can not have\",\n",
        "    \"'cause\": \"because\",\n",
        "    \"could've\": \"could have\",\n",
        "    \"couldn't\": \"could not\",\n",
        "    \"couldn't've\": \"could not have\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"doesn't\": \"does not\",\n",
        "    \"don't\": \"do not\",\n",
        "    \"hadn't\": \"had not\",\n",
        "    \"hadn't've\": \"had not have\",\n",
        "    \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\",\n",
        "    \"he'd\": \"he would\",\n",
        "    \"he'd've\": \"he would have\",\n",
        "    \"he'll\": \"he will\",\n",
        "    \"he'll've\": \"he will have\",\n",
        "    \"he's\": \"he is\",\n",
        "    \"how'd\": \"how did\",\n",
        "    \"how'd'y\": \"how do you\",\n",
        "    \"how'll\": \"how will\",\n",
        "    \"how's\": \"how is\",\n",
        "    \"i'd\": \"i would\",\n",
        "    \"i'd've\": \"i would have\",\n",
        "    \"i'll\": \"i will\",\n",
        "    \"i'll've\": \"i will have\",\n",
        "    \"i'm\": \"i am\",\n",
        "    \"i've\": \"i have\",\n",
        "    \"isn't\": \"is not\",\n",
        "    \"it'd\": \"it would\",\n",
        "    \"it'd've\": \"it would have\",\n",
        "    \"it'll\": \"it will\",\n",
        "    \"it'll've\": \"it will have\",\n",
        "    \"it's\": \"it is\",\n",
        "    \"let's\": \"let us\",\n",
        "    \"ma'am\": \"madam\",\n",
        "    \"mayn't\": \"may not\",\n",
        "    \"might've\": \"might have\",\n",
        "    \"mightn't\": \"might not\",\n",
        "    \"mightn't've\": \"might not have\",\n",
        "    \"must've\": \"must have\",\n",
        "    \"mustn't\": \"must not\",\n",
        "    \"mustn't've\": \"must not have\",\n",
        "    \"needn't\": \"need not\",\n",
        "    \"needn't've\": \"need not have\",\n",
        "    \"o'clock\": \"of the clock\",\n",
        "    \"oughtn't\": \"ought not\",\n",
        "    \"oughtn't've\": \"ought not have\",\n",
        "    \"shan't\": \"shall not\",\n",
        "    \"sha'n't\": \"shall not\",\n",
        "    \"shan't've\": \"shall not have\",\n",
        "    \"she'd\": \"she would\",\n",
        "    \"she'd've\": \"she would have\",\n",
        "    \"she'll\": \"she will\",\n",
        "    \"she'll've\": \"she will have\",\n",
        "    \"she's\": \"she is\",\n",
        "    \"should've\": \"should have\",\n",
        "    \"shouldn't\": \"should not\",\n",
        "    \"shouldn't've\": \"should not have\",\n",
        "    \"so've\": \"so have\",\n",
        "    \"so's\": \"so as\",\n",
        "    \"that'd\": \"that would\",\n",
        "    \"that'd've\": \"that would have\",\n",
        "    \"that's\": \"that is\",\n",
        "    \"there'd\": \"there would\",\n",
        "    \"there'd've\": \"there would have\",\n",
        "    \"there's\": \"there is\",\n",
        "    \"they'd\": \"they would\",\n",
        "    \"they'd've\": \"they would have\",\n",
        "    \"they'll\": \"they will\",\n",
        "    \"they'll've\": \"they will have\",\n",
        "    \"they're\": \"they are\",\n",
        "    \"they've\": \"they have\",\n",
        "    \"to've\": \"to have\",\n",
        "    \"wasn't\": \"was not\",\n",
        "    \"we'd\": \"we would\",\n",
        "    \"we'd've\": \"we would have\",\n",
        "    \"we'll\": \"we will\",\n",
        "    \"we'll've\": \"we will have\",\n",
        "    \"we're\": \"we are\",\n",
        "    \"we've\": \"we have\",\n",
        "    \"weren't\": \"were not\",\n",
        "    \"what'll\": \"what will\",\n",
        "    \"what'll've\": \"what will have\",\n",
        "    \"what're\": \"what are\",\n",
        "    \"what's\": \"what is\",\n",
        "    \"what've\": \"what have\",\n",
        "    \"when's\": \"when is\",\n",
        "    \"when've\": \"when have\",\n",
        "    \"where'd\": \"where did\",\n",
        "    \"where's\": \"where is\",\n",
        "    \"where've\": \"where have\",\n",
        "    \"who'll\": \"who will\",\n",
        "    \"who'll've\": \"who will have\",\n",
        "    \"who's\": \"who is\",\n",
        "    \"who've\": \"who have\",\n",
        "    \"why's\": \"why is\",\n",
        "    \"why've\": \"why have\",\n",
        "    \"will've\": \"will have\",\n",
        "    \"won't\": \"will not\",\n",
        "    \"won't've\": \"will not have\",\n",
        "    \"would've\": \"would have\",\n",
        "    \"wouldn't\": \"would not\",\n",
        "    \"wouldn't've\": \"would not have\",\n",
        "    \"y'all\": \"you all\",\n",
        "    \"y'all'd\": \"you all would\",\n",
        "    \"y'all'd've\": \"you all would have\",\n",
        "    \"y'all're\": \"you all are\",\n",
        "    \"y'all've\": \"you all have\",\n",
        "    \"you'd\": \"you would\",\n",
        "    \"you'd've\": \"you would have\",\n",
        "    \"you'll\": \"you will\",\n",
        "    \"you'll've\": \"you will have\",\n",
        "    \"you're\": \"you are\",\n",
        "    \"you've\": \"you have\"\n",
        "    }\n",
        "\n",
        "    q_decontracted = []\n",
        "\n",
        "    for word in q.split():\n",
        "        if word in contractions:\n",
        "            word = contractions[word]\n",
        "\n",
        "        q_decontracted.append(word)\n",
        "\n",
        "    q = ' '.join(q_decontracted)\n",
        "    q = q.replace(\"'ve\", \" have\")\n",
        "    q = q.replace(\"n't\", \" not\")\n",
        "    q = q.replace(\"'re\", \" are\")\n",
        "    q = q.replace(\"'ll\", \" will\")\n",
        "    \n",
        "    # Removing HTML tags\n",
        "    q = BeautifulSoup(q)\n",
        "    q = q.get_text()\n",
        "    \n",
        "    # Remove punctuations\n",
        "    pattern = re.compile('\\W')\n",
        "    q = re.sub(pattern, ' ', q).strip()\n",
        "\n",
        "    \n",
        "    return q\n",
        "    "
      ],
      "metadata": {
        "id": "7io5fMFrysGM"
      },
      "id": "7io5fMFrysGM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['question1'] = new_df['question1'].apply(preprocess)\n",
        "new_df['question2'] = new_df['question2'].apply(preprocess)"
      ],
      "metadata": {
        "id": "d1m8-dduzGZZ"
      },
      "id": "d1m8-dduzGZZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Advanced Features\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def fetch_token_features(row):\n",
        "    \n",
        "    q1 = row['question1']\n",
        "    q2 = row['question2']\n",
        "    \n",
        "    SAFE_DIV = 0.0001 \n",
        "\n",
        "    STOP_WORDS = stopwords.words(\"english\")\n",
        "    \n",
        "    token_features = [0.0]*8\n",
        "    \n",
        "    # Converting the Sentence into Tokens: \n",
        "    q1_tokens = q1.split()\n",
        "    q2_tokens = q2.split()\n",
        "    \n",
        "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
        "        return token_features\n",
        "\n",
        "    # Get the non-stopwords in Questions\n",
        "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
        "    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n",
        "    \n",
        "    #Get the stopwords in Questions\n",
        "    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n",
        "    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n",
        "    \n",
        "    # Get the common non-stopwords from Question pair\n",
        "    common_word_count = len(q1_words.intersection(q2_words))\n",
        "    \n",
        "    # Get the common stopwords from Question pair\n",
        "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
        "    \n",
        "    # Get the common Tokens from Question pair\n",
        "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
        "    \n",
        "    \n",
        "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
        "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
        "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
        "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
        "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
        "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
        "    \n",
        "    # Last word of both question is same or not\n",
        "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
        "    \n",
        "    # First word of both question is same or not\n",
        "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
        "    \n",
        "    return token_features"
      ],
      "metadata": {
        "id": "sQ-lPwGUzKfZ"
      },
      "id": "sQ-lPwGUzKfZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_features = new_df.apply(fetch_token_features, axis=1)\n",
        "\n",
        "new_df[\"cwc_min\"]       = list(map(lambda x: x[0], token_features))\n",
        "new_df[\"cwc_max\"]       = list(map(lambda x: x[1], token_features))\n",
        "new_df[\"csc_min\"]       = list(map(lambda x: x[2], token_features))\n",
        "new_df[\"csc_max\"]       = list(map(lambda x: x[3], token_features))\n",
        "new_df[\"ctc_min\"]       = list(map(lambda x: x[4], token_features))\n",
        "new_df[\"ctc_max\"]       = list(map(lambda x: x[5], token_features))\n",
        "new_df[\"last_word_eq\"]  = list(map(lambda x: x[6], token_features))\n",
        "new_df[\"first_word_eq\"] = list(map(lambda x: x[7], token_features))"
      ],
      "metadata": {
        "id": "PGiiElXvzRKb"
      },
      "id": "PGiiElXvzRKb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import distance\n",
        "\n",
        "def fetch_length_features(row):\n",
        "    \n",
        "    q1 = row['question1']\n",
        "    q2 = row['question2']\n",
        "    \n",
        "    length_features = [0.0]*3\n",
        "    \n",
        "    # Converting the Sentence into Tokens: \n",
        "    q1_tokens = q1.split()\n",
        "    q2_tokens = q2.split()\n",
        "    \n",
        "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
        "        return length_features\n",
        "    \n",
        "    # Absolute length features\n",
        "    length_features[0] = abs(len(q1_tokens) - len(q2_tokens))\n",
        "    \n",
        "    #Average Token Length of both Questions\n",
        "    length_features[1] = (len(q1_tokens) + len(q2_tokens))/2\n",
        "    \n",
        "    strs = list(distance.lcsubstrings(q1, q2))\n",
        "    length_features[2] = len(strs[0]) / (min(len(q1), len(q2)) + 1)\n",
        "    \n",
        "    return length_features"
      ],
      "metadata": {
        "id": "WAZvSfulzTdo"
      },
      "id": "WAZvSfulzTdo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length_features = new_df.apply(fetch_length_features, axis=1)\n",
        "\n",
        "new_df['abs_len_diff'] = list(map(lambda x: x[0], length_features))\n",
        "new_df['mean_len'] = list(map(lambda x: x[1], length_features))\n",
        "new_df['longest_substr_ratio'] = list(map(lambda x: x[2], length_features))"
      ],
      "metadata": {
        "id": "vIFeHwagzVo4"
      },
      "id": "vIFeHwagzVo4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fuzzy Features\n",
        "from fuzzywuzzy import fuzz\n",
        "\n",
        "def fetch_fuzzy_features(row):\n",
        "    \n",
        "    q1 = row['question1']\n",
        "    q2 = row['question2']\n",
        "    \n",
        "    fuzzy_features = [0.0]*4\n",
        "    \n",
        "    # fuzz_ratio\n",
        "    fuzzy_features[0] = fuzz.QRatio(q1, q2)\n",
        "\n",
        "    # fuzz_partial_ratio\n",
        "    fuzzy_features[1] = fuzz.partial_ratio(q1, q2)\n",
        "\n",
        "    # token_sort_ratio\n",
        "    fuzzy_features[2] = fuzz.token_sort_ratio(q1, q2)\n",
        "\n",
        "    # token_set_ratio\n",
        "    fuzzy_features[3] = fuzz.token_set_ratio(q1, q2)\n",
        "\n",
        "    return fuzzy_features"
      ],
      "metadata": {
        "id": "PHZpCLUBzXoA"
      },
      "id": "PHZpCLUBzXoA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fuzzy_features = new_df.apply(fetch_fuzzy_features, axis=1)\n",
        "\n",
        "# Creating new feature columns for fuzzy features\n",
        "new_df['fuzz_ratio'] = list(map(lambda x: x[0], fuzzy_features))\n",
        "new_df['fuzz_partial_ratio'] = list(map(lambda x: x[1], fuzzy_features))\n",
        "new_df['token_sort_ratio'] = list(map(lambda x: x[2], fuzzy_features))\n",
        "new_df['token_set_ratio'] = list(map(lambda x: x[3], fuzzy_features))"
      ],
      "metadata": {
        "id": "hMWXfQfAzafV"
      },
      "id": "hMWXfQfAzafV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(new_df[['ctc_min', 'cwc_min', 'csc_min', 'is_duplicate']],hue='is_duplicate')"
      ],
      "metadata": {
        "id": "jl0e7wA6zc4c"
      },
      "id": "jl0e7wA6zc4c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(new_df[['ctc_max', 'cwc_max', 'csc_max', 'is_duplicate']],hue='is_duplicate')"
      ],
      "metadata": {
        "id": "hLj62edlzf36"
      },
      "id": "hLj62edlzf36",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(new_df[['last_word_eq', 'first_word_eq', 'is_duplicate']],hue='is_duplicate')"
      ],
      "metadata": {
        "id": "tV4JQqqhzhgm"
      },
      "id": "tV4JQqqhzhgm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(new_df[['mean_len', 'abs_len_diff','longest_substr_ratio', 'is_duplicate']],hue='is_duplicate')"
      ],
      "metadata": {
        "id": "iwzcAakezjPA"
      },
      "id": "iwzcAakezjPA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(new_df[['fuzz_ratio', 'fuzz_partial_ratio','token_sort_ratio','token_set_ratio', 'is_duplicate']],hue='is_duplicate')"
      ],
      "metadata": {
        "id": "t4wwxzLZzkpE"
      },
      "id": "t4wwxzLZzkpE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using TSNE for Dimentionality reduction for 15 Features(Generated after cleaning the data) to 3 dimention\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X = MinMaxScaler().fit_transform(new_df[['cwc_min', 'cwc_max', 'csc_min', 'csc_max' , 'ctc_min' , 'ctc_max' , 'last_word_eq', 'first_word_eq' , 'abs_len_diff' , 'mean_len' , 'token_set_ratio' , 'token_sort_ratio' ,  'fuzz_ratio' , 'fuzz_partial_ratio' , 'longest_substr_ratio']])\n",
        "y = new_df['is_duplicate'].values"
      ],
      "metadata": {
        "id": "yNkahbKczmbB"
      },
      "id": "yNkahbKczmbB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "tsne2d = TSNE(\n",
        "    n_components=2,\n",
        "    init='random', # pca\n",
        "    random_state=101,\n",
        "    method='barnes_hut',\n",
        "    n_iter=1000,\n",
        "    verbose=2,\n",
        "    angle=0.5\n",
        ").fit_transform(X)"
      ],
      "metadata": {
        "id": "grV6tmfczrR4"
      },
      "id": "grV6tmfczrR4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_df = pd.DataFrame({'x':tsne2d[:,0], 'y':tsne2d[:,1] ,'label':y})\n",
        "\n",
        "# draw the plot in appropriate place in the grid\n",
        "sns.lmplot(data=x_df, x='x', y='y', hue='label', fit_reg=False, size=8,palette=\"Set1\",markers=['s','o'])"
      ],
      "metadata": {
        "id": "VRCp6tn-zszP"
      },
      "id": "VRCp6tn-zszP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tsne3d = TSNE(\n",
        "    n_components=3,\n",
        "    init='random', # pca\n",
        "    random_state=101,\n",
        "    method='barnes_hut',\n",
        "    n_iter=1000,\n",
        "    verbose=2,\n",
        "    angle=0.5\n",
        ").fit_transform(X)"
      ],
      "metadata": {
        "id": "GZPTNnIczu7r"
      },
      "id": "GZPTNnIczu7r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objs as go\n",
        "import plotly.tools as tls\n",
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "trace1 = go.Scatter3d(\n",
        "    x=tsne3d[:,0],\n",
        "    y=tsne3d[:,1],\n",
        "    z=tsne3d[:,2],\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        sizemode='diameter',\n",
        "        color = y,\n",
        "        colorscale = 'Portland',\n",
        "        colorbar = dict(title = 'duplicate'),\n",
        "        line=dict(color='rgb(255, 255, 255)'),\n",
        "        opacity=0.75\n",
        "    )\n",
        ")\n",
        "\n",
        "data=[trace1]\n",
        "layout=dict(height=800, width=800, title='3d embedding with engineered features')\n",
        "fig=dict(data=data, layout=layout)\n",
        "py.iplot(fig, filename='3DBubble')"
      ],
      "metadata": {
        "id": "ZIoetBnszytR"
      },
      "id": "ZIoetBnszytR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ques_df = new_df[['question1','question2']]\n",
        "ques_df.head()"
      ],
      "metadata": {
        "id": "qxBzuEh9z1zz"
      },
      "id": "qxBzuEh9z1zz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = new_df.drop(columns=['id','qid1','qid2','question1','question2'])\n",
        "print(final_df.shape)\n",
        "final_df.head()"
      ],
      "metadata": {
        "id": "QLZmJi3q0Bfw"
      },
      "id": "QLZmJi3q0Bfw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# merge texts\n",
        "questions = list(ques_df['question1']) + list(ques_df['question2'])\n",
        "\n",
        "cv = CountVectorizer(max_features=3000)\n",
        "q1_arr, q2_arr = np.vsplit(cv.fit_transform(questions).toarray(),2)"
      ],
      "metadata": {
        "id": "VkDmR6g50DCa"
      },
      "id": "VkDmR6g50DCa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df1 = pd.DataFrame(q1_arr, index= ques_df.index)\n",
        "temp_df2 = pd.DataFrame(q2_arr, index= ques_df.index)\n",
        "temp_df = pd.concat([temp_df1, temp_df2], axis=1)\n",
        "temp_df.shape"
      ],
      "metadata": {
        "id": "GbgqqJLb0E6_"
      },
      "id": "GbgqqJLb0E6_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.concat([final_df, temp_df], axis=1)\n",
        "print(final_df.shape)\n",
        "final_df.head()"
      ],
      "metadata": {
        "id": "g8FjwEjL0GfB"
      },
      "id": "g8FjwEjL0GfB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(final_df.iloc[:,1:].values,final_df.iloc[:,0].values,test_size=0.2,random_state=1)"
      ],
      "metadata": {
        "id": "tMVEJXVG0INu"
      },
      "id": "tMVEJXVG0INu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train,y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "P-ynFeCB0LMS"
      },
      "id": "P-ynFeCB0LMS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "xgb = XGBClassifier()\n",
        "xgb.fit(X_train,y_train)\n",
        "y_pred1 = xgb.predict(X_test)\n",
        "accuracy_score(y_test,y_pred1)"
      ],
      "metadata": {
        "id": "wgz2e9Q20MfT"
      },
      "id": "wgz2e9Q20MfT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test,y_pred)"
      ],
      "metadata": {
        "id": "87czakGN0amM"
      },
      "id": "87czakGN0amM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test,y_pred1)"
      ],
      "metadata": {
        "id": "n0fCTJyr0gHH"
      },
      "id": "n0fCTJyr0gHH",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}